{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coloc import coloc, print_coloc_result\n",
    "import pandas as pd\n",
    "from subprocess import call\n",
    "import itertools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASE_file = \"/mnt/hpc/home/xuxinran/DirectSeq/data/zhaolin_240206/240201-zhaolin-RNA-merge/v0.7.2/ASE/nano_merge_ASE_SNP.csv\"\n",
    "m6A_file = \"/mnt/hpc/home/xuxinran/DirectSeq/data/zhaolin_240206/240201-zhaolin-RNA-merge/v0.7.2/m6A/nano_merge_m6A_SNP.csv\"\n",
    "pseU_file = \"/mnt/hpc/home/xuxinran/DirectSeq/data/zhaolin_240206/240201-zhaolin-RNA-merge/v0.7.2/pseU/nano_merge_pseU_SNP.csv\"\n",
    "stability_file = \"/mnt/hpc/home/xuxinran/DirectSeq/data/zhaolin_240206/240201-zhaolin-RNA-merge/v0.7.2/stability/nano_merge_stability_SNP.csv\"\n",
    "isoform_file = \"/mnt/hpc/home/xuxinran/DirectSeq/data/zhaolin_240206/240201-zhaolin-RNA-merge/v0.7.2/isoform/nano_merge_isoform_SNP.csv\"\n",
    "polyA_file = \"/mnt/hpc/home/xuxinran/DirectSeq/data/zhaolin_240206/240201-zhaolin-RNA-merge/v0.7.2/apa/nano_merge_polyA_SNP.csv\"\n",
    "promoter_file = \"/mnt/hpc/home/xuxinran/DirectSeq/data/zhaolin_240206/240201-zhaolin-RNA-merge/v0.7.2/promoter/nano_merge_promoter_SNP.csv\"\n",
    "tss_file = \"/mnt/hpc/home/xuxinran/DirectSeq/data/zhaolin_240206/240201-zhaolin-RNA-merge/v0.7.2/tss/nano_merge_tss_SNP.csv\"\n",
    "\n",
    "gene_bed_file = \"/mnt/hpc/home/xuxinran/DirectSeq/data/zhaolin_240206/240201-zhaolin-RNA-merge/v0.7.2/stability/gene_merge.bed\"\n",
    "outdir = \"/mnt/hpc/home/xuxinran/DirectSeq/data/zhaolin_240206/240201-zhaolin-RNA-merge/v0.7.2/colco\"\n",
    "\n",
    "chrom = \"chr1\"\n",
    "strand = \"+\"\n",
    "min_qtl_count=25\n",
    "n = 104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_abf(se, beta, maf, n):\n",
    "    Z = np.abs(beta / se)\n",
    "    r = 1 / (n * maf * (1 - maf) * se**2) # Calculate shrinkage factor\n",
    "    abf = np.sqrt(1 - r) * np.exp((Z**2 / 2) * r)\n",
    "    return abf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(n, chrom, strand, full_summury, trait, trait_col=''):\n",
    "    df = pd.read_csv(full_summury)\n",
    "    df = df[(df['chrom'] == chrom)&(df['strand'] == strand)]\n",
    "    df = df[df['p_value']<1]\n",
    "    df[f'abf_{trait}'] = df.apply(lambda row: calculate_abf(row['SE'], row['beta'], row['EAF'], n), axis=1)\n",
    "    df = df.dropna(subset=[f'abf_{trait}'])\n",
    "    df = df.rename(columns={'p_value': f'p_value_{trait}'})\n",
    "    common_col = ['rsID', 'chrom', 'snp_pos_1base', 'strand', 'EAF', f'abf_{trait}', f'p_value_{trait}']\n",
    "    if trait_col:\n",
    "        common_col.append(trait_col)\n",
    "    df = df[common_col]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16034/973432080.py:4: RuntimeWarning: invalid value encountered in sqrt\n",
      "  abf = np.sqrt(1 - r) * np.exp((Z**2 / 2) * r)\n",
      "/tmp/ipykernel_16034/973432080.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  abf = np.sqrt(1 - r) * np.exp((Z**2 / 2) * r)\n",
      "/tmp/ipykernel_16034/2043148308.py:2: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(full_summury)\n",
      "/tmp/ipykernel_16034/973432080.py:4: RuntimeWarning: invalid value encountered in sqrt\n",
      "  abf = np.sqrt(1 - r) * np.exp((Z**2 / 2) * r)\n",
      "/tmp/ipykernel_16034/2043148308.py:2: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(full_summury)\n",
      "/tmp/ipykernel_16034/973432080.py:4: RuntimeWarning: invalid value encountered in sqrt\n",
      "  abf = np.sqrt(1 - r) * np.exp((Z**2 / 2) * r)\n",
      "/tmp/ipykernel_16034/973432080.py:4: RuntimeWarning: invalid value encountered in sqrt\n",
      "  abf = np.sqrt(1 - r) * np.exp((Z**2 / 2) * r)\n",
      "/tmp/ipykernel_16034/973432080.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  abf = np.sqrt(1 - r) * np.exp((Z**2 / 2) * r)\n",
      "/tmp/ipykernel_16034/973432080.py:4: RuntimeWarning: invalid value encountered in sqrt\n",
      "  abf = np.sqrt(1 - r) * np.exp((Z**2 / 2) * r)\n",
      "/tmp/ipykernel_16034/973432080.py:4: RuntimeWarning: invalid value encountered in sqrt\n",
      "  abf = np.sqrt(1 - r) * np.exp((Z**2 / 2) * r)\n",
      "/tmp/ipykernel_16034/973432080.py:4: RuntimeWarning: invalid value encountered in sqrt\n",
      "  abf = np.sqrt(1 - r) * np.exp((Z**2 / 2) * r)\n",
      "/tmp/ipykernel_16034/973432080.py:4: RuntimeWarning: invalid value encountered in sqrt\n",
      "  abf = np.sqrt(1 - r) * np.exp((Z**2 / 2) * r)\n"
     ]
    }
   ],
   "source": [
    "## 读所有的文件\n",
    "ASE_df = read_file(n, chrom, strand, ASE_file, \"ASE\")\n",
    "m6A_df = read_file(n, chrom, strand, m6A_file, \"m6A\", \"m6A_pos_1base\")\n",
    "pseU_df = read_file(n, chrom, strand, pseU_file, \"pseU\", \"pseU_pos_1base\")\n",
    "stability_df = read_file(n, chrom, strand, stability_file, \"stability\")\n",
    "isoform_df = read_file(n, chrom, strand, isoform_file, \"isoform\")\n",
    "polyA_df = read_file(n, chrom, strand, polyA_file, \"polyA\")\n",
    "promoter_df = read_file(n, chrom, strand, promoter_file, \"promoter\")\n",
    "tss_df = read_file(n, chrom, strand, tss_file, \"tss\")\n",
    "\n",
    "## 合并所有的 DataFrame\n",
    "dfs = [ASE_df, stability_df, isoform_df, polyA_df, promoter_df, tss_df, m6A_df, pseU_df]\n",
    "merged_df = dfs[0]\n",
    "for df in dfs[1:]:\n",
    "    merged_df = pd.merge(merged_df, df, on=['rsID', 'chrom', 'snp_pos_1base', 'strand', 'EAF'], how='outer')\n",
    "merged_df['non_null_count'] = merged_df.notnull().sum(axis=1) # 统计每行的非空值数量\n",
    "merged_df = merged_df[merged_df['non_null_count'] >= 10]  # 4列键 + 至少2种trait(6列)，保证这个SNP至少是两种QTL\n",
    "merged_df = merged_df.drop(columns=['non_null_count'])\n",
    "\n",
    "## gene注释\n",
    "gene_df = merged_df[['chrom', 'snp_pos_1base', 'strand', 'rsID']]\n",
    "gene_df = gene_df.drop_duplicates()\n",
    "gene_df['snp_pos_0base'] = gene_df['snp_pos_1base'] - 1\n",
    "gene_df['score'] = 0\n",
    "gene_df = gene_df[['chrom', 'snp_pos_0base', 'snp_pos_1base', 'rsID', 'score', 'strand']]\n",
    "gene_df.to_csv(f'{outdir}/rs_{chrom}_{strand}.bed', sep='\\t', index=False, header=False)\n",
    "call(f'bedtools intersect -wa -wb -s -a {outdir}/rs_{chrom}_{strand}.bed -b {gene_bed_file} > {outdir}/gene_rs_{chrom}_{strand}.bed',shell=True)\n",
    "gene_df = pd.read_csv(f'{outdir}/gene_rs_{chrom}_{strand}.bed',header=None,sep='\\t',usecols = [0,2,3,5,9],names=['chrom','snp_pos_1base','rsID','strand','geneID'])\n",
    "merged_df = pd.merge(merged_df, gene_df[['chrom', 'snp_pos_1base', 'rsID', 'strand', 'geneID']], on=['chrom', 'snp_pos_1base', 'rsID', 'strand'], how='left')\n",
    "call(f'rm {outdir}/rs_{chrom}_{strand}.bed {outdir}/gene_rs_{chrom}_{strand}.bed',shell=True)\n",
    "\n",
    "## 分区进行colco\n",
    "gene_groups = merged_df.groupby('geneID')\n",
    "\n",
    "for gene_group in gene_groups:\n",
    "    geneID = gene_group[0]\n",
    "    gene_df = gene_group[1]\n",
    "    # 筛选1:首先对gene整体筛选 保证gene内至少有min_qtl_count个重叠QTL\n",
    "    if len(set(gene_df['snp_pos_1base'])) >= min_qtl_count:\n",
    "        # 运行下面的函数\n",
    "        break\n",
    "    else:\n",
    "        # print(f\"{geneID} has less than {min_qtl_count} shared QTLs, skip\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trait_columns = ['tss', 'promoter', 'polyA', 'isoform', 'stability', 'm6A', 'pseU', 'ASE']\n",
    "for col in trait_columns:\n",
    "    gene_df[col] = gene_df[f'p_value_{col}'].notna()\n",
    "## 下面用来生成所有两两trait组合的df\n",
    "sub_dfs = {}\n",
    "for trait1, trait2 in itertools.combinations(trait_columns, 2):\n",
    "    sub_df = gene_df[(gene_df[trait1] != False) & (gene_df[trait2] != False)]\n",
    "    if len(set(sub_df['snp_pos_1base'])) >= min_qtl_count :\n",
    "        sub_dfs[f\"{trait1}_{trait2}\"] = sub_df # 筛选2：两两trait组合的SNP数量大于阈值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_2trait_combiner(geneID, gene_df, min_qtl_count=50, p_threshold=0.05):\n",
    "    trait_columns = ['tss', 'promoter', 'polyA', 'isoform', 'stability', 'm6A', 'pseU', 'ASE']\n",
    "    for col in trait_columns:\n",
    "        gene_df[col] = gene_df[f'p_value_{col}'].notna()\n",
    "    ## 下面用来生成所有两两trait组合的df\n",
    "    sub_dfs = {}\n",
    "    for trait1, trait2 in itertools.combinations(trait_columns, 2):\n",
    "        sub_df = gene_df[(gene_df[trait1] != False) & (gene_df[trait2] != False)]\n",
    "        if len(set(sub_df['snp_pos_1base'])) >= min_qtl_count :\n",
    "            sub_dfs[f\"{trait1}_{trait2}\"] = sub_df # 筛选2：两两trait组合的SNP数量大于阈值\n",
    "    if len(sub_dfs) == 0:\n",
    "        print(f'In {geneID},all trait combinations has less than {min_qtl_count} shared QTLs')\n",
    "        return None\n",
    "    else:\n",
    "        # 运行snp_combiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sub_dfs['m6A_pseU']\n",
    "trait1 = 'm6A'\n",
    "trait2 = 'pseU'\n",
    "df = df[[\"chrom\" , \"snp_pos_1base\", \"rsID\", \"strand\", \"EAF\", f\"abf_{trait1}\", f\"p_value_{trait1}\", f\"abf_{trait2}\", f\"p_value_{trait2}\"]]\n",
    "df = df.drop_duplicates()\n",
    "unique_snps = df[df.duplicated('snp_pos_1base', keep=False) == False]\n",
    "duplicate_snps = df[df.duplicated('snp_pos_1base', keep=False)]\n",
    "grouped = duplicate_snps.groupby('snp_pos_1base')\n",
    "groups = [group.index.tolist() for _, group in grouped] # 提取每个重复 SNP 的所有行\n",
    "for group in groups:\n",
    "    duplicate_sub_df = duplicate_snps.loc[group]\n",
    "    colco_sub_df = pd.concat([unique_snps, duplicate_sub_df])\n",
    "    ## 筛选3: 保证每个SNP的两个trait中 至少有一个p_value<0.05\n",
    "    if (colco_sub_df[f\"p_value_{trait1}\"] > 0.05).all() and (colco_sub_df[f\"p_value_{trait2}\"] > 0.05).all():\n",
    "        continue\n",
    "    else:\n",
    "        ## 进行snp_combiner\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snp_combiner(df, trait1, trait2, p_threshold=0.05):\n",
    "    df = df[[\"chrom\" , \"snp_pos_1base\", \"rsID\", \"strand\", \"EAF\", f\"abf_{trait1}\", f\"p_value_{trait1}\", f\"abf_{trait2}\", f\"p_value_{trait2}\"]]\n",
    "    df = df.drop_duplicates()\n",
    "    unique_snps = df[df.duplicated('snp_pos_1base', keep=False) == False]\n",
    "    duplicate_snps = df[df.duplicated('snp_pos_1base', keep=False)]\n",
    "    grouped = duplicate_snps.groupby('snp_pos_1base')\n",
    "    groups = [group.index.tolist() for _, group in grouped] # 提取每个重复 SNP 的所有行\n",
    "    for group in groups:\n",
    "        duplicate_sub_df = duplicate_snps.loc[group]\n",
    "        colco_sub_df = pd.concat([unique_snps, duplicate_sub_df])\n",
    "        ## 筛选3: 保证每个SNP的两个trait中 至少有一个p_value<0.05\n",
    "        if (colco_sub_df[f\"p_value_{trait1}\"] > p_threshold).all() and (colco_sub_df[f\"p_value_{trait2}\"] > p_threshold).all():\n",
    "            continue\n",
    "        else:\n",
    "            ## 进行snp_combiner\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = coloc(trait1_lnbfs=colco_sub_df['abf_m6A'],trait2_lnbfs=colco_sub_df['abf_pseU'],prior1=1e-3,prior2=1e-3,prior12=1e-4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8704316162265129,\n",
       " 0.05636531124196337,\n",
       " 0.05448740339774299,\n",
       " 0.0033749567290424502,\n",
       " 0.01534071240473844]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function print_coloc_result in module coloc.coloc:\n",
      "\n",
      "print_coloc_result(title: str, pp0: float, pp1: float, pp2: float, pp3: float, pp4: float)\n",
      "    Print an ascii representation of the colocalization test result\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    title\n",
      "        a title for the ascii art\n",
      "    pp0\n",
      "        the posterior probability of H0: no association\n",
      "    pp1\n",
      "        the posterior probability of H1: association in trait 1 only\n",
      "    pp2\n",
      "        the posterior probability of H2: association in trait 2 only\n",
      "    pp3\n",
      "        the posterior probability of H3: independent associations\n",
      "    pp4\n",
      "        the posterior probability of H4: colocalized associations\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(print_coloc_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "not colocalized\n",
      "\n",
      "PP0: [|||||||||||||||||   ] [ 0.8704316162265129 ]\n",
      "PP1: [|                   ] [ 0.05636531124196337 ]\n",
      "PP2: [|                   ] [ 0.05448740339774299 ]\n",
      "PP3: [                    ] [ 0.0033749567290424502 ]\n",
      "PP4: [                    ] [ 0.01534071240473844 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_coloc_result('not colocalized', *res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_coloc_analysis(colco_sub_df,prior1_set=1e-4 ,prior2_set=1e-4 ,prior12_set=1e-5):\n",
    "    result = coloc.coloc(\n",
    "    trait1_lnbfs=LBFs_trait1,\n",
    "    trait2_lnbfs=LBFs_trait2,\n",
    "    prior1=prior1_set,\n",
    "    prior2=prior2_set,\n",
    "    prior12=prior12_set,\n",
    ")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "methy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
